# =============================================================================
# LlamaIndex Agents - Environment Configuration
# =============================================================================
# Copy this file to .env and fill in your values
# =============================================================================

# -----------------------------------------------------------------------------
# OpenAI Configuration (Required)
# -----------------------------------------------------------------------------
OPENAI_API_KEY=your-openai-api-key
OPENAI_API_BASE=https://api.openai.com/v1

# -----------------------------------------------------------------------------
# LLM Defaults (Optional)
# -----------------------------------------------------------------------------
DEFAULT_MODEL=gpt-4.1-nano
DEFAULT_TEMPERATURE=0.0

# -----------------------------------------------------------------------------
# Perplexity Configuration (Optional - for ResearchAgent)
# -----------------------------------------------------------------------------
PERPLEXITY_API_KEY=your-perplexity-api-key
PERPLEXITY_API_BASE_URL=https://api.perplexity.ai
PERPLEXITY_MODEL=sonar

# -----------------------------------------------------------------------------
# Database Configuration (Optional - for persistent memory)
# -----------------------------------------------------------------------------
# PostgreSQL connection string for persistent memory and workflow states
# If not set, uses in-memory storage (data lost on restart)
MEMORY_DATABASE_URI=postgresql+asyncpg://postgres:password@localhost:5432/agents

# Connection pool settings
DB_POOL_SIZE=10
DB_MAX_OVERFLOW=20
DB_POOL_RECYCLE=3600

# Memory token limit per session
MEMORY_TOKEN_LIMIT=40000

# -----------------------------------------------------------------------------
# Observability - Arize Phoenix (Optional)
# -----------------------------------------------------------------------------
# Enable/disable Phoenix tracing
PHOENIX_ENABLED=true

# Phoenix collector endpoint (default: http://localhost:6006)
PHOENIX_ENDPOINT=http://localhost:6006

# Project name shown in Phoenix UI
PHOENIX_PROJECT_NAME=llamaindex-agents

# Use batch processor for production (async exports)
# Set to true for production, false for development (sync exports)
PHOENIX_BATCH_PROCESSOR=false
